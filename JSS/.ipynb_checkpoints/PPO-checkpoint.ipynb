{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have detected 80 CPUs here, so I'm going to create 79 actors\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import multiprocessing as mp\n",
    "import plotly.io as pio\n",
    "import ray\n",
    "from ray import tune\n",
    "\n",
    "from JSS.CustomCallbacks import CustomCallbacks\n",
    "from JSS.env.JSS import JSS\n",
    "from ray.rllib.agents.ppo import ppo, PPOTrainer\n",
    "\n",
    "from JSS.env_wrapper import BestActionsWrapper\n",
    "\n",
    "from JSS.models import FCMaskedActionsModel\n",
    "\n",
    "pio.orca.config.use_xvfb = True\n",
    "import wandb\n",
    "import torch\n",
    "\n",
    "'''\n",
    "            'lr': {\n",
    "                'values': [5e-5, 1e-5]\n",
    "            },\n",
    "            'lambda': {\n",
    "                'values': [0.90, 0.95, 1.0]\n",
    "            },\n",
    "            'clip_param': {\n",
    "                'values': [0.2, 0.3, 0.4]\n",
    "            },\n",
    "            'num_sgd_iter': {\n",
    "                'values': [30, 35, 40]\n",
    "            },\n",
    "            'entropy_coeff': {\n",
    "                'values': [0.0, 1e-4]\n",
    "            }\n",
    "'''\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"I have detected {} CPUs here, so I'm going to create {} actors\".format(mp.cpu_count(), mp.cpu_count() - 1))\n",
    "    os.environ[\"WANDB_API_KEY\"] = '3487a01956bf67cc7882bca2a38f70c8c95f8463'\n",
    "    sweep_config = {\n",
    "        'program': 'train.py',\n",
    "        'method': 'grid',\n",
    "        'metric': {\n",
    "            'name': 'time_step_min',\n",
    "            'goal': 'minimize',\n",
    "        },\n",
    "        'parameters': {\n",
    "            'instance_path': {\n",
    "                'values': ['/JSS/JSS/env/instances/ta51']\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: 46yrem10\n",
      "Sweep URL: https://wandb.ai/ingambe/RLLIB_SWEEP_4/sweeps/46yrem10\n"
     ]
    }
   ],
   "source": [
    "sweep_id = wandb.sweep(sweep_config, project=\"RLLIB_SWEEP_4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Starting wandb agent üïµÔ∏è\n",
      "2020-11-17 14:38:36,324 - wandb.wandb_agent - INFO - Running runs: []\n",
      "2020-11-17 14:38:36,625 - wandb.wandb_agent - INFO - Agent received command: run\n",
      "2020-11-17 14:38:36,625 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
      "\tinstance_path: /JSS/JSS/env/instances/ta51\n",
      "2020-11-17 14:38:36,627 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --instance_path=/JSS/JSS/env/instances/ta51\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mingambe\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mbright-sweep-1\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_4\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_4/sweeps/46yrem10\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_4/runs/gqfqwjvf\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in /JSS/JSS/wandb/run-20201117_143838-gqfqwjvf\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
      "\n",
      "2020-11-17 14:38:40,277\tINFO services.py:1090 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n",
      "2020-11-17 14:38:41,643 - wandb.wandb_agent - INFO - Running runs: ['gqfqwjvf']\n",
      "== Status ==\n",
      "Memory usage on this node: 20.4/754.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.03 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /root/ray_results/ppo-jss\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-------------------------+----------+-------+\n",
      "| Trial name              | status   | loc   |\n",
      "|-------------------------+----------+-------|\n",
      "| PPO_jss_env_35380_00000 | RUNNING  |       |\n",
      "+-------------------------+----------+-------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=49755)\u001b[0m 2020-11-17 14:38:44,082\tINFO trainer.py:617 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=49753)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=49753)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=49684)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=49684)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=49735)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=49735)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=49728)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=49728)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=49701)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=49701)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=49707)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=49707)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=49726)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=49726)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=49671)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=49671)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=49745)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=49745)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=49722)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=49722)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=49732)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=49732)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=49729)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=49729)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=49740)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=49740)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=49688)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=49688)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=49693)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=49693)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=49743)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=49743)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=49682)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=49682)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=49709)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=49709)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=49716)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=49716)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=49704)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=49704)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=49686)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=49686)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=49748)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=49748)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=49697)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=49697)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=49710)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=49710)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=49689)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=49689)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=49698)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=49698)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=49738)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=49738)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=49696)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=49696)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=49679)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=49679)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=49685)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=49685)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=49718)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=49718)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=49714)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=49714)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=49734)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=49734)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=49713)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=49713)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=49733)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=49733)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=49758)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=49758)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=49717)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=49717)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=49669)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=49669)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=49724)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=49724)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=49739)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=49739)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=49751)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=49751)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=49692)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=49692)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=49694)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=49694)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=49681)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=49681)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=49737)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=49737)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=49705)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=49705)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=49643)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=49643)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=49640)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=49640)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=49723)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=49723)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=49706)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=49706)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=49691)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=49691)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=49655)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=49655)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=49647)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=49647)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=49635)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=49635)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=49652)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=49652)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=49651)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=49651)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=49637)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=49637)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=49641)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=49641)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=49673)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=49673)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=49631)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=49631)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=49632)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=49632)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=49639)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=49639)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=49638)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=49638)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=49644)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=49644)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=49658)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=49658)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=49646)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=49646)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=49690)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=49690)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=49650)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=49650)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=49683)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=49683)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=49634)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=49634)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=49677)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=49677)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=49642)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=49642)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=49633)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=49633)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=49656)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=49656)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=49636)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=49636)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=49720)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=49720)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=49674)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=49674)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=49687)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=49687)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "\u001b[2m\u001b[36m(pid=49712)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729061180/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=49712)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "Result for PPO_jss_env_35380_00000:\n",
      "  custom_metrics:\n",
      "    time_step_max: 4029\n",
      "    time_step_mean: 3615.8104265402844\n",
      "    time_step_min: 3359\n",
      "  date: 2020-11-17_14-39-31\n",
      "  done: false\n",
      "  episode_len_mean: 889.253164556962\n",
      "  episode_reward_max: 265.2626262626266\n",
      "  episode_reward_mean: 217.51169927119273\n",
      "  episode_reward_min: 145.7171717171716\n",
      "  episodes_this_iter: 237\n",
      "  episodes_total: 237\n",
      "  experiment_id: 7e36b3b4fbf24329a559da211b871fd4\n",
      "  experiment_tag: '0'\n",
      "  hostname: f85e62b52919\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_kl_coeff: 0.29999999999999993\n",
      "        cur_lr: 0.00010000000000000002\n",
      "        entropy: 1.1510274807612102\n",
      "        entropy_coeff: 0.0010000000000000005\n",
      "        kl: 0.012884382220606009\n",
      "        model: {}\n",
      "        policy_loss: -0.024333837752540905\n",
      "        total_loss: 19130.906510416666\n",
      "        vf_explained_var: 0.3524645268917084\n",
      "        vf_loss: 9565.4642578125\n",
      "    num_steps_sampled: 210753\n",
      "    num_steps_trained: 210753\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 172.17.0.14\n",
      "  num_healthy_workers: 79\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 33.92608695652175\n",
      "    gpu_util_percent0: 0.31673913043478263\n",
      "    gpu_util_percent1: 0.8704347826086959\n",
      "    gpu_util_percent2: 0.0\n",
      "    ram_util_percent: 4.77608695652174\n",
      "    vram_util_percent0: 0.07857529910020393\n",
      "    vram_util_percent1: 0.9949178691351301\n",
      "    vram_util_percent2: 0.0\n",
      "  pid: 49755\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.16413793822487985\n",
      "    mean_env_wait_ms: 1.1648507010190259\n",
      "    mean_inference_ms: 5.5129441132028445\n",
      "    mean_raw_obs_processing_ms: 0.4119493798850834\n",
      "  time_since_restore: 39.02756333351135\n",
      "  time_this_iter_s: 39.02756333351135\n",
      "  time_total_s: 39.02756333351135\n",
      "  timers:\n",
      "    learn_throughput: 8624.568\n",
      "    learn_time_ms: 24436.355\n",
      "    sample_throughput: 14516.946\n",
      "    sample_time_ms: 14517.723\n",
      "    update_time_ms: 30.993\n",
      "  timestamp: 1605620371\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 210753\n",
      "  training_iteration: 1\n",
      "  trial_id: '35380_00000'\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 37.1/754.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.03 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /root/ray_results/ppo-jss\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-------------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name              | status   | loc               |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-------------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_jss_env_35380_00000 | RUNNING  | 172.17.0.14:49755 |      1 |          39.0276 | 210753 |  217.512 |              265.263 |              145.717 |            889.253 |\n",
      "+-------------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "Result for PPO_jss_env_35380_00000:\n",
      "  custom_metrics:\n",
      "    time_step_max: 4042\n",
      "    time_step_mean: 3613.604910714286\n",
      "    time_step_min: 3329\n",
      "  date: 2020-11-17_14-40-03\n",
      "  done: false\n",
      "  episode_len_mean: 893.4493670886076\n",
      "  episode_reward_max: 265.2626262626266\n",
      "  episode_reward_mean: 217.54718066743362\n",
      "  episode_reward_min: 132.08080808080743\n",
      "  episodes_this_iter: 237\n",
      "  episodes_total: 474\n",
      "  experiment_id: 7e36b3b4fbf24329a559da211b871fd4\n",
      "  experiment_tag: '0'\n",
      "  hostname: f85e62b52919\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_kl_coeff: 0.29999999999999993\n",
      "        cur_lr: 9.262364500000002e-05\n",
      "        entropy: 1.1410595099131267\n",
      "        entropy_coeff: 0.004483655150000001\n",
      "        kl: 0.014138526345292727\n",
      "        model: {}\n",
      "        policy_loss: -0.02251671180129051\n",
      "        total_loss: 14415.678125\n",
      "        vf_explained_var: 0.500388503074646\n",
      "        vf_loss: 7207.850716145834\n",
      "    num_steps_sampled: 423495\n",
      "    num_steps_trained: 423495\n",
      "  iterations_since_restore: 2\n",
      "  node_ip: 172.17.0.14\n",
      "  num_healthy_workers: 79\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 20.794736842105262\n",
      "    gpu_util_percent0: 0.39999999999999997\n",
      "    gpu_util_percent1: 0.8723684210526316\n",
      "    gpu_util_percent2: 0.0\n",
      "    ram_util_percent: 5.068421052631578\n",
      "    vram_util_percent0: 0.0947031813709413\n",
      "    vram_util_percent1: 0.9949178691351301\n",
      "    vram_util_percent2: 0.0\n",
      "  pid: 49755\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.16242142318431554\n",
      "    mean_env_wait_ms: 1.1635519255979265\n",
      "    mean_inference_ms: 5.3570157278267505\n",
      "    mean_raw_obs_processing_ms: 0.4118117597694951\n",
      "  time_since_restore: 70.81466889381409\n",
      "  time_this_iter_s: 31.787105560302734\n",
      "  time_total_s: 70.81466889381409\n",
      "  timers:\n",
      "    learn_throughput: 8614.231\n",
      "    learn_time_ms: 24581.125\n",
      "    sample_throughput: 19716.365\n",
      "    sample_time_ms: 10739.682\n",
      "    update_time_ms: 35.168\n",
      "  timestamp: 1605620403\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 423495\n",
      "  training_iteration: 2\n",
      "  trial_id: '35380_00000'\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 37.8/754.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.03 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /root/ray_results/ppo-jss\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-------------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name              | status   | loc               |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-------------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_jss_env_35380_00000 | RUNNING  | 172.17.0.14:49755 |      2 |          70.8147 | 423495 |  217.547 |              265.263 |              132.081 |            893.449 |\n",
      "+-------------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "Result for PPO_jss_env_35380_00000:\n",
      "  custom_metrics:\n",
      "    time_step_max: 4042\n",
      "    time_step_mean: 3609.3401459854013\n",
      "    time_step_min: 3329\n",
      "  date: 2020-11-17_14-40-40\n",
      "  done: false\n",
      "  episode_len_mean: 891.7862165963431\n",
      "  episode_reward_max: 265.2626262626266\n",
      "  episode_reward_mean: 218.8429442100326\n",
      "  episode_reward_min: 132.08080808080743\n",
      "  episodes_this_iter: 237\n",
      "  episodes_total: 711\n",
      "  experiment_id: 7e36b3b4fbf24329a559da211b871fd4\n",
      "  experiment_tag: '0'\n",
      "  hostname: f85e62b52919\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_kl_coeff: 0.29999999999999993\n",
      "        cur_lr: 8.5177675e-05\n",
      "        entropy: 1.1300094604492188\n",
      "        entropy_coeff: 0.00396243725\n",
      "        kl: 0.013447184984882673\n",
      "        model: {}\n",
      "        policy_loss: -0.025492406201859316\n",
      "        total_loss: 10013.892643229166\n",
      "        vf_explained_var: 0.6016489863395691\n",
      "        vf_loss: 5006.95908203125\n",
      "    num_steps_sampled: 634060\n",
      "    num_steps_trained: 634060\n",
      "  iterations_since_restore: 3\n",
      "  node_ip: 172.17.0.14\n",
      "  num_healthy_workers: 79\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 30.372727272727275\n",
      "    gpu_util_percent0: 0.30818181818181817\n",
      "    gpu_util_percent1: 0.8718181818181822\n",
      "    gpu_util_percent2: 0.0\n",
      "    ram_util_percent: 5.074999999999999\n",
      "    vram_util_percent0: 0.0947031813709413\n",
      "    vram_util_percent1: 0.9949178691351303\n",
      "    vram_util_percent2: 0.0\n",
      "  pid: 49755\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.1607136216761741\n",
      "    mean_env_wait_ms: 1.1608984204420671\n",
      "    mean_inference_ms: 5.219355616755935\n",
      "    mean_raw_obs_processing_ms: 0.4063622279946584\n",
      "  time_since_restore: 107.52517676353455\n",
      "  time_this_iter_s: 36.71050786972046\n",
      "  time_total_s: 107.52517676353455\n",
      "  timers:\n",
      "    learn_throughput: 8649.194\n",
      "    learn_time_ms: 24436.189\n",
      "    sample_throughput: 18674.983\n",
      "    sample_time_ms: 11317.458\n",
      "    update_time_ms: 34.432\n",
      "  timestamp: 1605620440\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 634060\n",
      "  training_iteration: 3\n",
      "  trial_id: '35380_00000'\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 37.8/754.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.03 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /root/ray_results/ppo-jss\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-------------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name              | status   | loc               |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-------------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_jss_env_35380_00000 | RUNNING  | 172.17.0.14:49755 |      3 |          107.525 | 634060 |  218.843 |              265.263 |              132.081 |            891.786 |\n",
      "+-------------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "Result for PPO_jss_env_35380_00000:\n",
      "  custom_metrics:\n",
      "    time_step_max: 4042\n",
      "    time_step_mean: 3608.2353579175706\n",
      "    time_step_min: 3293\n",
      "  date: 2020-11-17_14-41-11\n",
      "  done: false\n",
      "  episode_len_mean: 892.6571729957806\n",
      "  episode_reward_max: 267.08080808080797\n",
      "  episode_reward_mean: 219.2486894259044\n",
      "  episode_reward_min: 125.8686868686864\n",
      "  episodes_this_iter: 237\n",
      "  episodes_total: 948\n",
      "  experiment_id: 7e36b3b4fbf24329a559da211b871fd4\n",
      "  experiment_tag: '0'\n",
      "  hostname: f85e62b52919\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_kl_coeff: 0.29999999999999993\n",
      "        cur_lr: 7.780789999999999e-05\n",
      "        entropy: 1.1187736829121908\n",
      "        entropy_coeff: 0.0034465529999999993\n",
      "        kl: 0.015421522470812002\n",
      "        model: {}\n",
      "        policy_loss: -0.024581533980866273\n",
      "        total_loss: 8451.272005208333\n",
      "        vf_explained_var: 0.6721379160881042\n",
      "        vf_loss: 4225.64794921875\n",
      "    num_steps_sampled: 846239\n",
      "    num_steps_trained: 846239\n",
      "  iterations_since_restore: 4\n",
      "  node_ip: 172.17.0.14\n",
      "  num_healthy_workers: 79\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 21.22162162162162\n",
      "    gpu_util_percent0: 0.38756756756756755\n",
      "    gpu_util_percent1: 0.8745945945945945\n",
      "    gpu_util_percent2: 0.0\n",
      "    ram_util_percent: 5.0918918918918905\n",
      "    vram_util_percent0: 0.0947031813709413\n",
      "    vram_util_percent1: 0.9949178691351303\n",
      "    vram_util_percent2: 0.0\n",
      "  pid: 49755\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.15960327118936468\n",
      "    mean_env_wait_ms: 1.1593544659040005\n",
      "    mean_inference_ms: 5.131007339263675\n",
      "    mean_raw_obs_processing_ms: 0.40404310275646804\n",
      "  time_since_restore: 138.92462253570557\n",
      "  time_this_iter_s: 31.39944577217102\n",
      "  time_total_s: 138.92462253570557\n",
      "  timers:\n",
      "    learn_throughput: 8659.498\n",
      "    learn_time_ms: 24430.949\n",
      "    sample_throughput: 20713.592\n",
      "    sample_time_ms: 10213.572\n",
      "    update_time_ms: 30.982\n",
      "  timestamp: 1605620471\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 846239\n",
      "  training_iteration: 4\n",
      "  trial_id: '35380_00000'\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 37.8/754.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.03 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /root/ray_results/ppo-jss\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-------------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name              | status   | loc               |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-------------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_jss_env_35380_00000 | RUNNING  | 172.17.0.14:49755 |      4 |          138.925 | 846239 |  219.249 |              267.081 |              125.869 |            892.657 |\n",
      "+-------------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "Result for PPO_jss_env_35380_00000:\n",
      "  custom_metrics:\n",
      "    time_step_max: 4042\n",
      "    time_step_mean: 3599.969801553063\n",
      "    time_step_min: 3293\n",
      "  date: 2020-11-17_14-41-48\n",
      "  done: false\n",
      "  episode_len_mean: 891.4059071729957\n",
      "  episode_reward_max: 267.08080808080797\n",
      "  episode_reward_mean: 220.28602480501195\n",
      "  episode_reward_min: 114.95959595959593\n",
      "  episodes_this_iter: 237\n",
      "  episodes_total: 1185\n",
      "  experiment_id: 7e36b3b4fbf24329a559da211b871fd4\n",
      "  experiment_tag: '0'\n",
      "  hostname: f85e62b52919\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_kl_coeff: 0.29999999999999993\n",
      "        cur_lr: 7.0381635e-05\n",
      "        entropy: 1.1078867514928181\n",
      "        entropy_coeff: 0.00292671445\n",
      "        kl: 0.013663651173313458\n",
      "        model: {}\n",
      "        policy_loss: -0.026022766903042793\n",
      "        total_loss: 6737.107845052084\n",
      "        vf_explained_var: 0.725005030632019\n",
      "        vf_loss: 3368.566471354167\n",
      "    num_steps_sampled: 1056316\n",
      "    num_steps_trained: 1056316\n",
      "  iterations_since_restore: 5\n",
      "  node_ip: 172.17.0.14\n",
      "  num_healthy_workers: 79\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 30.430232558139537\n",
      "    gpu_util_percent0: 0.36139534883720936\n",
      "    gpu_util_percent1: 0.874186046511628\n",
      "    gpu_util_percent2: 0.0\n",
      "    ram_util_percent: 5.07674418604651\n",
      "    vram_util_percent0: 0.0947031813709413\n",
      "    vram_util_percent1: 0.9949178691351303\n",
      "    vram_util_percent2: 0.0\n",
      "  pid: 49755\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.1587013685328426\n",
      "    mean_env_wait_ms: 1.1579950213054293\n",
      "    mean_inference_ms: 5.061169314801878\n",
      "    mean_raw_obs_processing_ms: 0.4011147039187845\n",
      "  time_since_restore: 175.44419527053833\n",
      "  time_this_iter_s: 36.519572734832764\n",
      "  time_total_s: 175.44419527053833\n",
      "  timers:\n",
      "    learn_throughput: 8670.105\n",
      "    learn_time_ms: 24366.856\n",
      "    sample_throughput: 19861.66\n",
      "    sample_time_ms: 10636.735\n",
      "    update_time_ms: 29.008\n",
      "  timestamp: 1605620508\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1056316\n",
      "  training_iteration: 5\n",
      "  trial_id: '35380_00000'\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 37.8/754.6 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.03 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /root/ray_results/ppo-jss\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name              | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_jss_env_35380_00000 | RUNNING  | 172.17.0.14:49755 |      5 |          175.444 | 1056316 |  220.286 |              267.081 |               114.96 |            891.406 |\n",
      "+-------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wandb agent 46yrem10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
